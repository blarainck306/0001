{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this note, I apply __L1-based__ feature selection. Note that due to its sparsed representaiton of the model, L1-based feature selectin is widely used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make data suitable for logistic regression (LR) algorithm, I have applied mean 0 and standard deviation for 'age' column, and midrange 0 and range 2 (i.e., minimum -1 and maximum 1) for other columns, inlcuding date time variables and all agreation (occurance counting) variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "import sklearn.grid_search\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "import math\n",
    "\n",
    "from NDCG_score_func import ndcg_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading X,y and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X= np.load('X.npy')\n",
    "y= np.load('y.npy')\n",
    "X_test= np.load('X_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection using logistic regression regularized with L1 norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Using grid function to do k-fold cross validation....\n",
    "#for each set of parameters, run K-fold cross validation\n",
    "C_iter =[0.1] #budget paramter.\n",
    "parameters = {'C':C_iter}\n",
    "LgR = sklearn.linear_model.LogisticRegression(penalty='l1') #n_jobs=-1\n",
    "clf = sklearn.grid_search.GridSearchCV(LgR, parameters, cv=2, n_jobs=1)\n",
    "clf.fit(X,y)\n",
    "a = clf.grid_scores_\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.64019, std: 0.00041, params: {'C': 0.1}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting from model: Using the best fitted estimator to perform feature selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clf.best_estimator_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12L, 226L)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_ .coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213451L, 226L)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213451L, 122L)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "lg = clf.best_estimator_ \n",
    "model = SelectFromModel(lg, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62096L, 122L)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_new = model.transform(X_test)\n",
    "X_test_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213451L, 226L)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance using __random forest__ with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.82005258  0.81832695  0.81880954  0.81861809  0.81940185]\n",
      "0.81904180069\n",
      "Wall time: 19min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#select m features out of p features randomly for each node\n",
    "#bootstropped used to boost the randomness of the each tree\n",
    "rf = RandomForestClassifier(max_features=35, n_estimators=120, n_jobs=1, min_samples_split=5)#n_jobs=2 #, min_samples_split=5  max_features=12\n",
    "#view the whole data set as trainning set, and cross validate using K-fold cross validata(K=10)\n",
    "kf = KFold(len(X_new), n_folds=5, random_state=42)\n",
    "score_list = cross_val_score(rf, X_new, y, cv=kf,scoring=ndcg_scorer)# scoring=ndcg_scorer\n",
    "print score_list\n",
    "print np.mean(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary: \n",
    "- 2 fold L1 C=0.01 0.1, 1, 10  NDCG=0.6356 0.64019,0.64115 ,0.64103,\n",
    "- selected feature:71 122, 177, 209\n",
    "- random forest with selected features:0.8180, 0.81904, 0.819467, 0.8195\n",
    "- test performance:0.87949 (rank 313) 0.88098 0.88077 0.88135 (rank 300?)\n",
    "- RF paramters: min_samples_split= 27,35,40,40\n",
    "\n",
    "Remark: \n",
    "- very similar in terms of performance. \n",
    "- Thourough cross validation for tunning RF parameters is not done, e.g., max_features. The used parameters are 35, 35,40 repectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating submission using the appraoch above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #get some useful paramters ready to use\n",
    "# df_train = pd.read_csv('train_users_2.csv')\n",
    "# df_test = pd.read_csv('test_users.csv')\n",
    "# labels = df_train['country_destination'].values\n",
    "# df_train = df_train.drop(['country_destination'], axis=1)\n",
    "\n",
    "\n",
    "# id_test = df_test['id']\n",
    "# piv_train = df_train.shape[0]\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# le.fit(labels) #is this  integer encoding a must-do or optional?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5uwns89zht</td>\n",
       "      <td>NDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5uwns89zht</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5uwns89zht</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5uwns89zht</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5uwns89zht</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id country\n",
       "0  5uwns89zht     NDF\n",
       "1  5uwns89zht      US\n",
       "2  5uwns89zht      IT\n",
       "3  5uwns89zht   other\n",
       "4  5uwns89zht      PT"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #set up classifier parameters\n",
    "# #number of n_estimators trees \n",
    "# rf = RandomForestClassifier(n_estimators = 120,max_features = 35, min_samples_split=5, n_jobs=-1)\n",
    "# rf.fit(X_new,y)\n",
    "# y_pred = rf.predict_proba(X_test_new)\n",
    "\n",
    "# #Taking the 5 classes with highest probabilities\n",
    "# ids = []  #list of ids\n",
    "# cts = []  #list of countries\n",
    "# for i in range(len(id_test)):\n",
    "#     #idx:internal variable \n",
    "#     idx = id_test[i] \n",
    "#     #dupliccate ids 5 times and put it to the list ids\n",
    "#     ids += [idx] * 5\n",
    "#     cts += le.inverse_transform(np.argsort(y_pred[i])[::-1])[:5].tolist()\n",
    "    \n",
    "# #Generate submission\n",
    "# sub = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\n",
    "# sub.to_csv('sub5.csv',index=False)\n",
    "# sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.88135 obtained similar to random forest selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next, I will try C=1 to check if more features will be ruled out and is the performance going to be changed. (Notice that I need to save the relavant variables for selected data and coffiencienit for later use regarding RF CV and selected feature inspection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (later)Also, L_2 can also be tried as L2 has advantage in sklearn faster implementation. One can use a pretuned threshold to implement this approache using a for loop cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: It is well known that Logistic regression (LR) is usually not suitable multi-class classification task, especially for imbalanced data set. As shown above, the accuacy is much poorer than Random Forest. But still we can use is a approach to do feature selection. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
